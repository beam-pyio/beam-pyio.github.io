<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Jaehyeon Kim on</title><link>/authors/jaehyeonkim/</link><description>Recent content in Jaehyeon Kim on</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright/><atom:link href="/authors/jaehyeonkim/index.xml" rel="self" type="application/rss+xml"/><item><title>DynamoDB PyIO Connector 0.1.1</title><link>/blog/2024/dynamodb-pyio-0.1.1/</link><pubDate>Tue, 24 Sep 2024 00:00:00 +0000</pubDate><guid>/blog/2024/dynamodb-pyio-0.1.1/</guid><description><![CDATA[<p>We are happy to present the first release of the <a href="https://github.com/beam-pyio/dynamodb_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon DynamoDB<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>
<p>✨NEW</p>
<ul>
<li>Add a composite transform (<code>WriteToDynamoDB</code>) that writes records to a DynamoDB table with help of the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/dynamodb/table/batch_writer.html" target="_blank" rel="noopener noreferrer"><code>batch_writer</code><i class="fas fa-external-link-square-alt ms-1"></i></a> of the boto3 package.
<ul>
<li>The batch writer will automatically handle buffering and sending items in batches. In addition, it will also automatically handle any unprocessed items and resend them as needed.</li>
</ul>
</li>
</ul>]]></description></item><item><title>Introduction to DynamoDB PyIO Sink Connector</title><link>/blog/2024/dynamodb-pyio-intro/</link><pubDate>Mon, 23 Sep 2024 00:00:00 +0000</pubDate><guid>/blog/2024/dynamodb-pyio-intro/</guid><description><![CDATA[<p><a href="https://aws.amazon.com/dynamodb/" target="_blank" rel="noopener noreferrer">Amazon DynamoDB<i class="fas fa-external-link-square-alt ms-1"></i></a> is a serverless, NoSQL database service that allows you to develop modern applications at any scale. The <a href="https://github.com/beam-pyio/dynamodb_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon DynamoDB<i class="fas fa-external-link-square-alt ms-1"></i></a> (<code>dynamodb_pyio</code>) aims to integrate with the database service by supporting source and sink connectors. Currently, the sink connector is available.</p>]]></description></item><item><title>Firehose PyIO Connector 0.2.1</title><link>/blog/2024/firehose-pyio-0.2.1/</link><pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate><guid>/blog/2024/firehose-pyio-0.2.1/</guid><description><![CDATA[<p>We are happy to present the <a href="https://github.com/beam-pyio/firehose_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon Data Firehose<i class="fas fa-external-link-square-alt ms-1"></i></a> 0.2.1 release.</p>
<p>♻️UPDATE</p>
<ul>
<li>Return failed elements by a tagged output, which allows users to determine how to handle them subsequently.</li>
<li>Provide options that handle failed records.
<ul>
<li><em>max_trials</em> - The maximum number of trials when there is one or more failed records.</li>
<li><em>append_error</em> - Whether to append error details to failed records.</li>
</ul>
</li>
</ul>]]></description></item><item><title>SQS PyIO Connector 0.1.0</title><link>/blog/2024/sqs-pyio-0.1.0/</link><pubDate>Tue, 20 Aug 2024 00:00:00 +0000</pubDate><guid>/blog/2024/sqs-pyio-0.1.0/</guid><description><![CDATA[<p>We are happy to present the first release of the <a href="https://github.com/beam-pyio/sqs_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon SQS<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>
<p>✨NEW</p>
<ul>
<li>Add a composite transform (<code>WriteToSqs</code>) that sends messages to a SQS queue in batch, using the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sqs/client/send_message_batch.html" target="_blank" rel="noopener noreferrer"><code>send_message_batch</code><i class="fas fa-external-link-square-alt ms-1"></i></a> method of the boto3 package.</li>
</ul>]]></description></item><item><title>Introduction to SQS PyIO Sink Connector</title><link>/blog/2024/sqs-pyio-intro/</link><pubDate>Mon, 19 Aug 2024 00:00:00 +0000</pubDate><guid>/blog/2024/sqs-pyio-intro/</guid><description><![CDATA[<p><a href="https://aws.amazon.com/sqs/" target="_blank" rel="noopener noreferrer">Amazon Simple Queue Service (Amazon SQS)<i class="fas fa-external-link-square-alt ms-1"></i></a> offers a secure, durable, and available hosted queue that lets you integrate and decouple distributed software systems and components. The <a href="https://github.com/beam-pyio/sqs_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon SQS<i class="fas fa-external-link-square-alt ms-1"></i></a> (<code>sqs_pyio</code>) aims to integrate with the queue service by supporting source and sink connectors. Currently, the sink connector is available.</p>]]></description></item><item><title>Firehose PyIO Connector 0.1.0</title><link>/blog/2024/firehose-pyio-0.1.0/</link><pubDate>Fri, 19 Jul 2024 00:00:00 +0000</pubDate><guid>/blog/2024/firehose-pyio-0.1.0/</guid><description><![CDATA[<p>We are happy to present the first release of the <a href="https://github.com/beam-pyio/firehose_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon Data Firehose<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>
<p>✨NEW</p>
<ul>
<li>Add a composite transform (<code>WriteToFirehose</code>) that puts records into a Firehose delivery stream in batch, using the <a href="https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/firehose/client/put_record_batch.html" target="_blank" rel="noopener noreferrer"><code>put_record_batch</code><i class="fas fa-external-link-square-alt ms-1"></i></a> method of the boto3 package.</li>
</ul>]]></description></item><item><title>Introduction to Firehose PyIO Sink Connector</title><link>/blog/2024/firehose-pyio-intro/</link><pubDate>Thu, 18 Jul 2024 00:00:00 +0000</pubDate><guid>/blog/2024/firehose-pyio-intro/</guid><description><![CDATA[<p><a href="https://aws.amazon.com/firehose/" target="_blank" rel="noopener noreferrer">Amazon Data Firehose<i class="fas fa-external-link-square-alt ms-1"></i></a> is a fully managed service for delivering real-time streaming data to destinations such as Amazon Simple Storage Service (Amazon S3), Amazon Redshift, Amazon OpenSearch Service and Amazon OpenSearch Serverless. The <a href="https://github.com/beam-pyio/firehose_pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O connector for Amazon Data Firehose<i class="fas fa-external-link-square-alt ms-1"></i></a> (<code>firehose_pyio</code>) provides a data sink feature that facilitates integration with those services.</p>]]></description></item><item><title>Apache Beam Python I/O Connectors</title><link>/blog/2024/beam-pyio-intro/</link><pubDate>Thu, 04 Jul 2024 00:00:00 +0000</pubDate><guid>/blog/2024/beam-pyio-intro/</guid><description><![CDATA[<p><a href="https://beam.apache.org/" target="_blank" rel="noopener noreferrer">Apache Beam<i class="fas fa-external-link-square-alt ms-1"></i></a> is an open source unified programming model to define and execute data processing pipelines, including ETL, batch and stream processing. We consider it has a huge potential to improve traditional development patterns in both transactional and analytical processing of data. Specifically it can be applied to event-driven applications, data pipelines and streaming analytics.</p>
<p>Employing <a href="https://en.wikipedia.org/wiki/Dataflow_programming" target="_blank" rel="noopener noreferrer">dataflow programming<i class="fas fa-external-link-square-alt ms-1"></i></a>, Beam supports a range of <a href="https://beam.apache.org/documentation/io/connectors/" target="_blank" rel="noopener noreferrer">I/O connectors<i class="fas fa-external-link-square-alt ms-1"></i></a>, but we find some gaps in the existing connectors especially in relation to the Python SDK. It fueled us to start the <a href="https://github.com/beam-pyio" target="_blank" rel="noopener noreferrer">Apache Beam Python I/O Connectors<i class="fas fa-external-link-square-alt ms-1"></i></a> project.</p>]]></description></item></channel></rss>